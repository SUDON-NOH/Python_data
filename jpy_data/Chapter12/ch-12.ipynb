{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감성 분석 코드 고쳐보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify import accuracy\n",
    "\n",
    "import builtins\n",
    "\n",
    "try:\n",
    "    profile = builtins.profile\n",
    "except AttributeError:\n",
    "    def profile(func): \n",
    "        return func\n",
    "\n",
    "@profile\n",
    "def label_docs():\n",
    "    docs = [(list(movie_reviews.words(fid)), cat)\n",
    "            for cat in movie_reviews.categories()\n",
    "            for fid in movie_reviews.fileids(cat)]\n",
    "    random.seed(42)\n",
    "    random.shuffle(docs)\n",
    "\n",
    "    return docs\n",
    "\n",
    "@profile\n",
    "def isStopWord(word):\n",
    "    return word in sw or len(word) == 1\n",
    "\n",
    "@profile\n",
    "def filter_corpus():\n",
    "    review_words = movie_reviews.words()\n",
    "    print(\"# Review Words\", len(review_words))\n",
    "    res = [w.lower() for w in review_words if not isStopWord(w.lower())]\n",
    "    print(\"# After filter\", len(res))\n",
    "\n",
    "    return res\n",
    "@profile\n",
    "def select_word_features(corpus):\n",
    "    words = FreqDist(corpus)\n",
    "    N = int(.02 * len(words.keys()))\n",
    "    return list(words.keys())[:N]\n",
    "\n",
    "@profile\n",
    "def doc_features(doc):\n",
    "    doc_words = FreqDist(w for w in doc if not isStopWord(w))\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['count (%s)' % word] = (doc_words.get(word, 0))\n",
    "    return features\n",
    "\n",
    "@profile\n",
    "def make_features(docs):\n",
    "    return [(doc_features(d), c) for (d,c) in docs]\n",
    "\n",
    "@profile\n",
    "def split_data(sets):\n",
    "    return sets[200:], sets[:200]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    labeled_docs = label_docs()\n",
    "\n",
    "    sw = set(stopwords.words('english'))\n",
    "    filtered = filter_corpus()\n",
    "    word_features = select_word_features(filtered)\n",
    "    featuresets = make_features(labeled_docs)\n",
    "    train_set, test_set = split_data(featuresets)\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "    print(\"Accuracy\", accuracy(classifier, test_set))\n",
    "    print(classifier.show_most_informative_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
